{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install chardet\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqFArlAhzvhh",
        "outputId": "f64d99e3-326c-4065-a947-dbaa9d5c0501"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: chardet in /usr/local/lib/python3.11/dist-packages (5.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import chardet\n",
        "\n",
        "file_path = \"/content/CPSC 572 Project Raw Dataset(Sheet1).csv\"\n",
        "\n",
        "with open(file_path, \"rb\") as f:\n",
        "    result = chardet.detect(f.read(100000))\n",
        "    print(\"Detected encoding:\", result[\"encoding\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6h-SoK0Qzywe",
        "outputId": "3e7c95ca-7e29-4cf1-9332-f6c3b66b4476"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected encoding: Windows-1252\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import chardet\n",
        "import time\n",
        "\n",
        "def get_coauthors(author_id, per_page=200):\n",
        "    \"\"\"\n",
        "    Fetch co-authors for a given author.\n",
        "    This function handles pagination and exceptions.\n",
        "    Note: Currently not used in the main workflow.\n",
        "    \"\"\"\n",
        "    url = f\"https://api.openalex.org/works?filter=authorships.author.id:{author_id}&per_page={per_page}\"\n",
        "    coauthors = set()\n",
        "    while url:\n",
        "        try:\n",
        "            response = requests.get(url)\n",
        "            response.raise_for_status()\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Error fetching co-authors for {author_id}: {e}\")\n",
        "            break\n",
        "\n",
        "        data = response.json()\n",
        "        for work in data.get(\"results\", []):\n",
        "            for authorship in work.get(\"authorships\", []):\n",
        "                author = authorship.get(\"author\", {})\n",
        "                if author and author.get(\"id\") != author_id:\n",
        "                    coauthors.add(author.get(\"display_name\", \"Unknown Co-author\"))\n",
        "\n",
        "        meta = data.get(\"meta\", {})\n",
        "        next_cursor = meta.get(\"next_cursor\")\n",
        "        if next_cursor:\n",
        "            url = (f\"https://api.openalex.org/works?filter=authorships.author.id:{author_id}\"\n",
        "                   f\"&per_page={per_page}&cursor={next_cursor}\")\n",
        "            time.sleep(1)\n",
        "        else:\n",
        "            url = None\n",
        "\n",
        "    return list(coauthors)\n",
        "\n",
        "def detect_encoding(file_path):\n",
        "    \"\"\"\n",
        "    Detect file encoding for reading CSV reliably.\n",
        "    \"\"\"\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        result = chardet.detect(f.read(100000))\n",
        "        return result[\"encoding\"]\n",
        "\n",
        "def get_author_details(author_id):\n",
        "    \"\"\"\n",
        "    Fetch detailed metadata about an author from OpenAlex.\n",
        "    \"\"\"\n",
        "    url = f\"https://api.openalex.org/authors/{author_id}\"\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        return response.json()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching author details for {author_id}: {e}\")\n",
        "        return {}\n",
        "\n",
        "def search_openalex_authors(name):\n",
        "    \"\"\"\n",
        "    Search authors by name.\n",
        "    Return the list of matching authors from the OpenAlex query.\n",
        "    \"\"\"\n",
        "    url = f\"https://api.openalex.org/authors?filter=display_name.search:{name}\"\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        return data.get(\"results\", [])\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching author {name}: {e}\")\n",
        "        return []\n",
        "\n",
        "def get_author_works(author_id, per_page=200):\n",
        "    \"\"\"\n",
        "    Fetch works for a given author.\n",
        "    This function handles pagination to retrieve all pages of results.\n",
        "    \"\"\"\n",
        "    works = []\n",
        "    url = f\"https://api.openalex.org/works?filter=authorships.author.id:{author_id}&per_page={per_page}\"\n",
        "    while url:\n",
        "        try:\n",
        "            response = requests.get(url)\n",
        "            response.raise_for_status()\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Error fetching works for {author_id}: {e}\")\n",
        "            break\n",
        "\n",
        "        data = response.json()\n",
        "        works.extend(data.get(\"results\", []))\n",
        "        meta = data.get(\"meta\", {})\n",
        "        next_cursor = meta.get(\"next_cursor\")\n",
        "        if next_cursor:\n",
        "            url = (f\"https://api.openalex.org/works?filter=authorships.author.id:{author_id}\"\n",
        "                   f\"&per_page={per_page}&cursor={next_cursor}\")\n",
        "            time.sleep(1)\n",
        "        else:\n",
        "            url = None\n",
        "    return works\n",
        "\n",
        "def get_affiliations_and_countries(author_dict):\n",
        "    \"\"\"\n",
        "    Gather affiliation and country code info from the 'affiliations'\n",
        "    field of the author record returned by a search query.\n",
        "    \"\"\"\n",
        "    affiliations = []\n",
        "    countries = []\n",
        "    affiliations_data = author_dict.get(\"affiliations\", [])\n",
        "    if isinstance(affiliations_data, list):\n",
        "        for affiliation in affiliations_data:\n",
        "            institution = affiliation.get(\"institution\", {})\n",
        "            name = institution.get(\"display_name\", \"Unknown Institution\")\n",
        "            country = institution.get(\"country_code\", \"Unknown Country\")\n",
        "            affiliations.append(name if name else \"\")\n",
        "            countries.append(country if country else \"\")\n",
        "    return affiliations, countries\n",
        "\n",
        "def analyze_coauthors_and_positions(author_id, works_data, valid_author_names):\n",
        "    \"\"\"\n",
        "    Analyze the target author's position (first/middle/last) in each work\n",
        "    and collect co-author relationships (including position data) only for those\n",
        "    co-authors whose names are in 'valid_author_names'.\n",
        "\n",
        "    Note: Currently filtering is done by display name because the CSV only\n",
        "    provides names. If unique identifiers were available, matching by ID\n",
        "    would be more reliable.\n",
        "    \"\"\"\n",
        "    total_works = 0\n",
        "    first_author_count = 0\n",
        "    last_author_count = 0\n",
        "    middle_author_count = 0\n",
        "    coauthor_details = {}\n",
        "\n",
        "    for work in works_data:\n",
        "        work_id = work.get(\"id\", \"\")\n",
        "        authorships = work.get(\"authorships\", [])\n",
        "        if not authorships:\n",
        "            continue\n",
        "\n",
        "        all_authors = []\n",
        "        target_index = None\n",
        "        for i, a in enumerate(authorships):\n",
        "            author_info = a.get(\"author\", {})\n",
        "            author_id_in_work = author_info.get(\"id\")\n",
        "            author_name = author_info.get(\"display_name\", \"Unknown\")\n",
        "            all_authors.append((author_id_in_work, author_name))\n",
        "            if author_id_in_work == author_id:\n",
        "                target_index = i\n",
        "\n",
        "        if target_index is not None:\n",
        "            total_works += 1\n",
        "            num_authors = len(all_authors)\n",
        "            if target_index == 0:\n",
        "                first_author_count += 1\n",
        "            elif target_index == num_authors - 1:\n",
        "                last_author_count += 1\n",
        "            else:\n",
        "                middle_author_count += 1\n",
        "\n",
        "            for i, (coauthor_id, coauthor_name) in enumerate(all_authors):\n",
        "                if coauthor_id and coauthor_id != author_id:\n",
        "                    if coauthor_name in valid_author_names:\n",
        "                        if coauthor_name not in coauthor_details:\n",
        "                            coauthor_details[coauthor_name] = []\n",
        "                        coauthor_details[coauthor_name].append(\n",
        "                            (work_id, target_index, i, num_authors)\n",
        "                        )\n",
        "    return {\n",
        "        \"total_works\": total_works,\n",
        "        \"first_author_count\": first_author_count,\n",
        "        \"last_author_count\": last_author_count,\n",
        "        \"middle_author_count\": middle_author_count,\n",
        "        \"coauthor_details\": coauthor_details\n",
        "    }\n",
        "\n",
        "def process_authors_from_csv(input_csv, output_csv):\n",
        "    \"\"\"\n",
        "    Reads author names from the first column of 'input_csv', fetches detailed data\n",
        "    from OpenAlex, filters co-authors to only those in the same CSV's list of authors,\n",
        "    and writes enriched data to 'output_csv'.\n",
        "    \"\"\"\n",
        "    encoding = detect_encoding(input_csv)\n",
        "    df = pd.read_csv(input_csv, encoding=encoding)\n",
        "    df = df[df.iloc[:, 0].notna()].copy()\n",
        "    df.iloc[:, 0] = df.iloc[:, 0].astype(str).str.strip()\n",
        "    valid_author_names = set(df.iloc[:, 0].tolist())\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for name in df.iloc[:, 0]:\n",
        "        if not name:\n",
        "            continue\n",
        "\n",
        "        authors_found = search_openalex_authors(name)\n",
        "        if not authors_found:\n",
        "            print(f\"No match found on OpenAlex for '{name}'.\")\n",
        "            results.append({\n",
        "                \"Author Queried\": name,\n",
        "                \"OpenAlex ID\": \"\",\n",
        "                \"Display Name (Best Match)\": \"\",\n",
        "                \"Works Count\": \"\",\n",
        "                \"Cited By Count\": \"\",\n",
        "                \"Affiliations\": \"\",\n",
        "                \"Country Codes\": \"\",\n",
        "                \"Authorship Summary\": \"\",\n",
        "                \"Coauthor Collaboration Details\": \"\"\n",
        "            })\n",
        "            continue\n",
        "\n",
        "        best_match = authors_found[0]\n",
        "        target_author_id = best_match.get(\"id\", \"\")\n",
        "        display_name = best_match.get(\"display_name\", \"\")\n",
        "\n",
        "        author_details = get_author_details(target_author_id)\n",
        "        works_count = author_details.get(\"works_count\", 0)\n",
        "        cited_by_count = author_details.get(\"cited_by_count\", 0)\n",
        "\n",
        "        works_data = get_author_works(target_author_id)\n",
        "        affiliations, countries = get_affiliations_and_countries(best_match)\n",
        "        authorship_stats = analyze_coauthors_and_positions(\n",
        "            author_id=target_author_id,\n",
        "            works_data=works_data,\n",
        "            valid_author_names=valid_author_names\n",
        "        )\n",
        "\n",
        "        authorship_summary = (\n",
        "            f\"Total works: {authorship_stats['total_works']}; \"\n",
        "            f\"First-author: {authorship_stats['first_author_count']}; \"\n",
        "            f\"Middle-author: {authorship_stats['middle_author_count']}; \"\n",
        "            f\"Last-author: {authorship_stats['last_author_count']}\"\n",
        "        )\n",
        "\n",
        "        coauthor_collab_info = {}\n",
        "        for coauthor, details in authorship_stats[\"coauthor_details\"].items():\n",
        "            coauthor_collab_info[coauthor] = [\n",
        "                {\n",
        "                    \"work_id\": d[0],\n",
        "                    \"target_author_position\": d[1],\n",
        "                    \"coauthor_position\": d[2],\n",
        "                    \"total_authors_in_work\": d[3]\n",
        "                }\n",
        "                for d in details\n",
        "            ]\n",
        "\n",
        "        results.append({\n",
        "            \"Author Queried\": name,\n",
        "            \"OpenAlex ID\": target_author_id,\n",
        "            \"Display Name (Best Match)\": display_name,\n",
        "            \"Works Count\": works_count,\n",
        "            \"Cited By Count\": cited_by_count,\n",
        "            \"Affiliations\": \"; \".join(filter(None, affiliations)),\n",
        "            \"Country Codes\": \"; \".join(filter(None, countries)),\n",
        "            \"Authorship Summary\": authorship_summary,\n",
        "            \"Coauthor Collaboration Details\": str(coauthor_collab_info)\n",
        "        })\n",
        "\n",
        "    output_df = pd.DataFrame(results)\n",
        "    output_df.to_csv(output_csv, index=False, encoding='utf-8-sig')\n",
        "    print(f\"Enriched results saved to '{output_csv}'.\")\n",
        "\n",
        "input_csv = \"/content/CPSC 572 Project Raw Dataset(Sheet1).csv\"\n",
        "output_csv = \"new_dataset.csv\"\n",
        "\n",
        "process_authors_from_csv(input_csv, output_csv)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-k3VEniteGG",
        "outputId": "9056d3fe-3697-40d6-db66-b10e758411a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No match found on OpenAlex for 'Jean E. Sammet'.\n",
            "No match found on OpenAlex for 'Manuela M. Veloso'.\n",
            "No match found on OpenAlex for 'Kathleen Antonelli'.\n",
            "No match found on OpenAlex for 'Rohini Kesavan Srihari'.\n",
            "No match found on OpenAlex for 'Daniela L. Rus'.\n",
            "No match found on OpenAlex for 'Frances Spence'.\n",
            "No match found on OpenAlex for 'Julie Beth Lovins'.\n",
            "No match found on OpenAlex for 'Cecilia R. Aragon'.\n",
            "No match found on OpenAlex for 'Ellen Fetter'.\n",
            "No match found on OpenAlex for 'Tracy Chou'.\n",
            "No match found on OpenAlex for 'Leslie P. Kaelbling'.\n",
            "No match found on OpenAlex for 'Jennifer Tour Chayes'.\n",
            "No match found on OpenAlex for 'Helen Chan Wolf'.\n",
            "No match found on OpenAlex for 'Milly Koss'.\n",
            "No match found on OpenAlex for 'Veronika Megler'.\n",
            "No match found on OpenAlex for 'Asuman Özda?lar'.\n",
            "No match found on OpenAlex for 'Maja Panti?'.\n",
            "No match found on OpenAlex for 'V?ra K?rková'.\n",
            "No match found on OpenAlex for 'Borka Jerman Blaži?'.\n",
            "No match found on OpenAlex for 'Nell B. Dale'.\n",
            "No match found on OpenAlex for 'Amy Ashurst Gooch'.\n",
            "No match found on OpenAlex for 'Andrea Grimes Parker'.\n",
            "No match found on OpenAlex for 'Magdalena Ba?azi?ska'.\n",
            "No match found on OpenAlex for 'Aleksandra Przegali?ska'.\n",
            "No match found on OpenAlex for 'Tülay Adal?'.\n",
            "No match found on OpenAlex for 'Ivona Brandi?'.\n",
            "No match found on OpenAlex for 'Mary Elizabeth Ramsay'.\n",
            "No match found on OpenAlex for 'Sibel Adal?'.\n",
            "No match found on OpenAlex for 'Maureen C. Stone'.\n",
            "No match found on OpenAlex for 'Maria L. Gini'.\n",
            "No match found on OpenAlex for 'Ellen W. Zegura'.\n",
            "No match found on OpenAlex for 'Gudrun J. Klinker'.\n",
            "No match found on OpenAlex for 'Margaret Philomena Rayman'.\n",
            "No match found on OpenAlex for 'Sandra A. Edwards'.\n",
            "No match found on OpenAlex for 'Alexandra Boer Kimball'.\n",
            "No match found on OpenAlex for 'Gillian Arnold'.\n",
            "No match found on OpenAlex for 'Solange Inês Mussatto'.\n",
            "No match found on OpenAlex for 'Janet Louise Taylor'.\n",
            "Enriched results saved to 'output.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_df = pd.DataFrame(results)\n",
        "output_df.to_csv(output_csv, index=False, encoding='utf-8-sig')\n",
        "print(f\"Results saved to {output_csv}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hi-YgJ5UZoG_",
        "outputId": "55cd6a11-ca60-4835-ba31-377fb3700ecf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results saved to output.csv\n"
          ]
        }
      ]
    }
  ]
}