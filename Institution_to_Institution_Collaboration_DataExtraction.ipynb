{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3g_h_4eSUHUn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "nodes_table = pd.read_excel(\"nodes_undirected.xlsx\")\n",
        "edges_table = pd.read_excel(\"edges_undirected.xlsx\")\n",
        "\n",
        "# Parse affiliations from semicolon-separated lists in the \"Affiliations\" column\n",
        "# Creates a list of institutions for each researcher\n",
        "nodes_table[\"affiliation_list\"] = nodes_table[\"Affiliations\"].fillna(\"\").apply(\n",
        "    lambda x: [aff.strip() for aff in x.split(\";\") if aff.strip()]\n",
        ")\n",
        "\n",
        "# Create a dictionary that maps each researcher (by ID) to their list of affiliated institutions\n",
        "author_affiliations = dict(zip(nodes_table[\"Id\"], nodes_table[\"affiliation_list\"]))\n",
        "\n",
        "# Define a function to generate all unique institution-to-institution pairs for a given co-authorship\n",
        "# Self-loops (same institution on both ends) are excluded\n",
        "def get_institution_pairs(row):\n",
        "    source_institutions = author_affiliations.get(row[\"Source\"], [])\n",
        "    target_institutions = author_affiliations.get(row[\"Target\"], [])\n",
        "    pairs = set()\n",
        "    for src in source_institutions:\n",
        "        for tgt in target_institutions:\n",
        "            if src != tgt:\n",
        "                pairs.add(tuple(sorted((src, tgt))))\n",
        "    return list(pairs)\n",
        "\n",
        "# Apply the pairing function to each edge in the network\n",
        "# Each co-authorship may produce multiple institution-level collaboration links\n",
        "edges_table[\"institution_pairs\"] = edges_table.apply(get_institution_pairs, axis=1)\n",
        "\n",
        "# Explode the list of institution pairs into separate rows (one row per institution-institution pair)\n",
        "edges_expanded = edges_table.explode(\"institution_pairs\").dropna(subset=[\"institution_pairs\"]).copy()\n",
        "\n",
        "# Split each institution pair tuple into two separate columns\n",
        "edges_expanded[[\"Institution_1\", \"Institution_2\"]] = pd.DataFrame(\n",
        "    edges_expanded[\"institution_pairs\"].tolist(), index=edges_expanded.index\n",
        ")\n",
        "\n",
        "# Group by institution pairs and sum the total weight (number of co-authorships)\n",
        "institution_collab_edges = (\n",
        "    edges_expanded.groupby([\"Institution_1\", \"Institution_2\"])[\"Weight\"].sum().reset_index()\n",
        ")\n",
        "\n",
        "# Save the final institution-to-institution collaboration network to CSV\n",
        "institution_collab_edges.to_csv(\"institution_collaborations.csv\", index=False)"
      ]
    }
  ]
}